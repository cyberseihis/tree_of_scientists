@document.meta
title: treescience
description: Multidimentional data structures class project
authors: dabbing
categories: ceid, software
created: 2022-12-28
updated: 2022-12-29
version: 0.0.15
@end

* Tree of scientists
  [Project description]{@ ProjectDefinitionNddata.pdf}
  Deadline: around finals period
  I chose project 1
** Problem definition
   Create multi-dimentional index structures for data of the form
   (surname: String, awards: Int, education: /text-vector/)
   scraped from [List of scientists]
   to be used for range queries on the first two fields
   and /LSH/ grouping on the last.
*** Structures
    - k-d trees
    - Quad trees
    - Range trees
    - R trees
*** Example
    Scientists with >60% simularity in education with names starting
    with \[A..G\] and have > 4 awards.

** Plan
   - [x] Scap data with python
   - [-] Cleanup data
   - [ ] Write _summary_ for the types of data structures
   - [ ] Dump data in csv
   - [ ] Turn education to /LSH/ hashes
   - [ ] Look for haskell data structure libraries
   - [ ] Implement data structures
   - [ ] Measure complexity for each structure
   Complexity here means ammount of operations/nodes accessed
   - [ ] Write report

** Data scraping
   [List of scientists]{https://en.wikipedia.org/wiki/List_of_computer_scientists}
   - [x] Search for wikipedia scraping
   Wikipedia-specific libraries don't have all the features needed
   - [x] Get list of links for wiki pages
   - [x] Search for web scraping in python
   Propably will use beatiful soup
   -Will download the html of the first page to get going-
   Just got all the links using developer tools in the browser
   - [x] Scrap surname
   - [x] Scrap ammount of awards
   - [x] Write scrap script for education
   - [x] Scrap education texts
   By education I understand the 'Education' section specifically.
   Do education seperately since it will be vectorised anyways
** Data cleanup
   - [ ] Merge name/award files
   - [ ] Merge with education file
   - [ ] Remove partial results
   - [ ] Formating
